\subsection{Tok tokena}

Компајлер поседује наизглед два лексера. Лексер ниског нивоа је \verb|rustc_lexer|, а лексер високог нивоа је \verb|rustc_parse::lexer|. 
Обе имплементације су важне јер \verb|rusc_parse::lexer| користи \verb|rustc_lexer| током компајлирања.

\subsubsection{rustc\_lexer}

\verb|rustc_lexer| је лексер ниског нивоа који поседује све основне
функционалности потребне приликом прикупљања лексема.
Главна функција из овог модула јесте \verb|tokenize| која на основу целокупног текста 
изворног кода добавља скуп токена тј. лексема \ref{lst:tokenize}.

\begin{listing}[H]
\begin{minted}{rust}
pub fn tokenize(input: &str) -> impl Iterator<Item = Token> + '_ {
    let mut cursor = Cursor::new(input);
    std::iter::from_fn(move || {
        let token = cursor.advance_token();
        if token.kind != TokenKind::Eof { Some(token) } else { None }
    })
}
\end{minted}
\caption{Улазна функција лексера}
\label{lst:tokenize}
\end{listing}

Имплементација је базирана на курсору и унутар те структуре се налази целокупна логика лексера. 
Курсор је реализован помоћу \verb|Rust|-овог итератора и на основу њега прати тренутну позицију 
унутар изворног кода. Веома је битна могућност гледања испред (\verb|look-ahead|) која омогућава 
извршавање у једном проласку.
Клонирање итератора је јефтина операција јер се своди на копирање тренутне адреса.

\begin{listing}[H]
\begin{minted}{rust}
    pub fn first(&self) -> char {
        // `.next()` optimizes better than `.nth(0)`
        self.chars.clone().next().unwrap_or(EOF_CHAR)
    }
    pub(crate) fn second(&self) -> char {
        let mut iter = self.chars.clone();
        iter.next();
        iter.next().unwrap_or(EOF_CHAR)
    }
    pub fn third(&self) -> char {
        let mut iter = self.chars.clone();
        iter.next();
        iter.next();
        iter.next().unwrap_or(EOF_CHAR)
    }
\end{minted}
\caption{"Look-ahead" механизам}
\end{listing}

\verb|Token| садржи само информацију о типу токен-а и његову дужину али не и 
сам податак.

\begin{listing}[H]
\begin{minted}{rust}
#[derive(Debug)]
pub struct Token {
    pub kind: TokenKind,
    pub len: u32,
}   
\end{minted}
\caption{Дефиниција "Token" структуре}
\end{listing}

\subsubsection{rustc\_parse::lexer}

Лексер вишег нивоа \verb|rustc_parse::lexer| користи \verb|rustc_lexer| приликом извршавања сопствених
операција. Битна разлика је то што се садржај токен анализира и поставља у контекст.
Лексер вишег нивоа користи курсор свог претходника за добављање лексема кроз структуру \verb|StringReader|. 

\begin{listing}[H]
\begin{minted}{rust}
    struct StringReader<'psess, 'src> {
        psess: &'psess ParseSess,
        start_pos: BytePos,
        pos: BytePos,
        src: &'src str,
        cursor: Cursor<'src>,
        override_span: Option<Span>,
        nbsp_is_whitespace: bool,
        last_lifetime: Option<Span>,
    }
\end{minted}
\caption{Дефиниција "StringReader" структуре}
\end{listing}

\verb|StringReader| прати тренутну позицију унутар изворног кода, а курсор 
добавља токен који има одређену дужину. Садржај токена је низ карактера са почетком у \verb|pos|,
дужине \verb|token.len|. 

Проласком кроз изворни код извршавају се следеће акције:
\begin{enumerate}
    \item Интернирање 
    \item Токени из \verb|rustc_lexer| се мапирају на токене из \verb|rustc_ast|
    \item Резулуција заграда свих типова.
    \item Проблеми и препоруке генеришу дијагностику 
\end{enumerate}

Интернирање је оптмизација перформанси и меморије где се вредности алоцирају унутар 
посебног алокатора који се назива \verb|arena|. Свака овако алоцирана вредност се преноси по 
референци што омогућава да се идентичне вредности у програму алоцирају једном. Поређења
су такође значајно јефтинија јер је могуће само поредити меморијске адресе. 
Интернирана вредност се назива симбол. Табела симбола је структура података
која складишти и омогућава О(1) приступ било ком симболу.  Табела симбола је имплементирана помоћу \verb|IndexSet|
структуре. Не интернира се сваки токен, већ само токени који имају варијабилну дужину значајне величине.

Приликом интернирања користи се \verb|SpanData| структура која има 16 бајта. Још једна структура која 
се користи јесте \verb|Span| која има 8 бајта што значи мање простора за дужину, родитеља и контекст. 
Процентуално, преко 99.9\%  \verb|SpanData| инстанци могу да стану у тих 8 бајта. Сваки \verb|SpanData|
чија поља не могу да испуне овај критеријум се чувају у табели симбола и \verb|Span| ће извлачити податке 
одатле. Интернирање је довољно ретко да је цена ниска, али довољно често да пружа побољшање. 
Раније верзије \verb|Rust| компајлера користиле су само 4 бајта за \verb|Span|, али то је било спорије 
јер се само 90\% \verb|Span|-ова могло садржати без приступања табели симбола.

\begin{listing}[H]
\begin{minted}{rust}
#[derive(Clone, Copy, Eq, PartialEq, Hash)]
#[rustc_pass_by_value]
pub struct Span {
    lo_or_index: u32,
    len_with_tag_or_marker: u16,
    ctxt_or_parent_or_marker: u16,
}
\end{minted}
\caption{Дефинциија "Span" структуре}
\end{listing}


\begin{listing}[H]
\begin{minted}{rust}
#[derive(Clone, Copy, Hash, PartialEq, Eq)]
#[derive_where(PartialOrd, Ord)]
pub struct SpanData {
    pub lo: BytePos,
    pub hi: BytePos,
    #[derive_where(skip)]
    pub ctxt: SyntaxContext,
    #[derive_where(skip)]
    pub parent: Option<LocalDefId>,
}
\end{minted}
\caption{Дефиниција "SpanData" структуре}
\end{listing}

Постоји четири различита формата \verb|Span|-а, \verb|inline|-\verb|context| формат, \verb|inline|-\verb|parent| формат,
\verb|partially|-\verb|interned| формат и \verb|fully-interned| формат.  Препознају се на основу вредности поља.

Мапирање токена из лексера у тип токена из апстрактног синтаксног стабла је тривиално.
За просте типове врши се један на један конверзија.

\begin{listing}[H]
\begin{minted}{rust}
    rustc_lexer::TokenKind::Semi => token::Semi,
    rustc_lexer::TokenKind::Comma => token::Comma,
    rustc_lexer::TokenKind::Dot => token::Dot,
\end{minted}
\caption{Превођење токена из лексера у АСТ токене}
\end{listing}

За типове који имају садржај у виду низова карактера, садржај се интернира и преноси 
у нови токен путем симбола \ref{lst:intern}. Деривати апстрактног синтаксног стабла се често користе приликом компајлирања и због тога 
стабло мора бити меморијски оптимизовано.

\begin{listing}[H]
\begin{minted}{rust}
    let ident = Symbol::intern(lifetime_name);
    token::Lifetime(ident, IdentIsRaw::No)
\end{minted}
\caption{Интернирање литерала}
\label{lst:intern}
\end{listing}

Ток токена је скуп стабала токена од којих је свако стабло сачињено од скупа токена.  
Резолуција заграда је процес унутар ког се валидира да ли је свака заграда правилно затворена.
Резолуција заграда се дешава у самом врху процеса \verb|rustc_parser::lexer|-а 
за време креирања тока токена. У контексту компајлера заграде се називају делимитери. 
Сваки отворени тип делимитера мора бити затворен делимитером истог типа који је затворен.
На пример, витичаста заграда је тип делимитера која може бити отворен (\{) или затворен (\}) тј.
свака отворена витичаста заграда мора бити затворена затвореном витичастом заградом.

\begin{listing}[H]
\begin{minted}{rust}
fn lex_token_trees(
    &mut self,
    is_delimited: bool,
) -> (Spacing, TokenStream, Result<(), Vec<PErr<'psess>>>) {
    // Move past the opening delimiter.
    let (_, open_spacing) = self.bump(false);
    let mut buf = Vec::new();
    loop {
        match self.token.kind {
            token::OpenDelim(delim) => buf.push(match self
            .lex_token_tree_open_delim(delim) {
                Ok(val) => val,
                Err(errs) => return (open_spacing, 
                TokenStream::new(buf), Err(errs)),
            }),
            token::CloseDelim(delim) => {
                return (
                    open_spacing,
                    TokenStream::new(buf),
                    if is_delimited { 
                        Ok(()) 
                    } else { Err(vec![self.close_delim_err(delim)]) },
                );
            }
            token::Eof => {
                return (
                    open_spacing,
                    TokenStream::new(buf),
                    if is_delimited { Err(vec![self.eof_err()]) } 
                    else { Ok(()) },
                );
            }
            _ => {
                // Get the next normal token.
                let (this_tok, this_spacing) = self.bump(true);
                buf.push(TokenTree::Token(this_tok, this_spacing));
    } } } }
\end{minted}
\caption{Генерисање стабла токена}
\end{listing}


Примећује се да у случају да када делимитер не постоји, додавање токена у ток токена 
је секвенцијално и не захтева никакву комплексну логику. Променљива \verb|is_delimited|
означава да ли тренутна секвенца токена припада неком пару делимитера. У случају да 
се наиђе на затворен тип делимитера без да је претходно постојао отворен, враћа се грешка
у виду дијагностике. У сличном контексту, наилазак на токен крај-а фајла без да је свака 
заграда затворена је грешка. 
Наиласком на \verb|token::Eof| или \verb|token::CloseDelim| се завршава прикупљање тока токена.
Ово су веома корисни гранични случајеви који омогућавају рекурзију. 

Обрада отвореног типа делимитера у позадини позива функцију \verb|lex_token_trees| који обрађује
стабло токена (део тока токена) између новог пара заграда.

\begin{listing}[H]
\begin{minted}{rust}
    fn lex_token_tree_open_delim(
        &mut self,
        open_delim: Delimiter,
    ) -> Result<TokenTree, Vec<PErr<'psess>>> {
        // The span for beginning of the delimited section.
        let pre_span = self.token.span;

        self.diag_info.open_braces.push((open_delim, self.token.span));

        // Lex the token trees within the delimiters.
        // We stop at any delimiter so we can try to recover if the user
        // uses an incorrect delimiter.
        let (open_spacing, tts, res) = self
                            .lex_token_trees(/* is_delimited */ true);
        if let Err(errs) = res {
            return Err(self.unclosed_delim_err(tts, errs));
        }

        // Expand to cover the entire delimited token tree.
        let delim_span = DelimSpan::from_pair(pre_span, self.token.span);
        let sm = self.string_reader.psess.source_map();

        let close_spacing = match self.token.kind {
        .
        .
        .
\end{minted}
\caption{Парсирање стабла токена}
\end{listing}

Необрађене заграде се чувају у структури \verb|TokenTreeDiagInfo| у пољу \verb|open_braces|.
Утврђено је да ће по успешном завршетку извршавања функције \verb|lex_token_trees| 
тренутни токен бити позициониран на затворени тип делимитер-а. То омогућава валидацију 
правилног завршетка заграда.